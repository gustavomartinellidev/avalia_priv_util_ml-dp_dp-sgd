# **Avalia√ß√£o entre Privacidade e Acur√°cia em Modelos de Deep Learning com DP-SGD**

Este reposit√≥rio cont√©m o c√≥digo-fonte utilizado no artigo:

**‚ÄúUma Avalia√ß√£o entre Privacidade e Acur√°cia em Modelos de Aprendizado Supervisionado em Deep Learning com DP-SGD (_Differentially Private Stochastic Gradient Descent_)‚Äù**

Autores:  
- **Gustavo Gobi Martinelli** ‚Äì gustavomartinelli@gmail.com  
- **Rodolfo da Silva Villa√ßa** ‚Äì rodolfo.villaca@inf.ufes.br  

O estudo investiga empiricamente o *trade-off* entre **privacidade diferencial** e **acur√°cia** no treinamento de modelos de aprendizado supervisionado, utilizando o dataset CIFAR-10 e a t√©cnica **DP-SGD**, implementada com a biblioteca **Opacus**.

O notebook completo est√° dispon√≠vel neste reposit√≥rio no arquivo **`avalia_priv_acc_ml-dp_dp-sgd.ipynb`**, bem como no Google Colab por meio do link abaixo (somente leitura):

üëâ **[Link do Colab (preencher aqui)]()**

---

## **üìå Objetivo do Projeto**

O prop√≥sito central deste experimento √© demonstrar, de forma reprodut√≠vel:

1. Como a inje√ß√£o de ru√≠do Gaussiano no processo de treinamento preserva privacidade sob o paradigma de **_Differential Privacy_**.  
2. Como diferentes n√≠veis de ru√≠do afetam a **acur√°cia**, a **converg√™ncia**, e o **Œµ (epsilon)** consumido.  
3. A compara√ß√£o direta entre:
   - **Treinamento tradicional (sem privacidade)**  
   - **Treinamento com DP-SGD** nos cen√°rios:
     - Privacidade Fraca  
     - Privacidade M√©dia  
     - Privacidade Forte  

As an√°lises incluem curvas de *loss*, acur√°cia, evolu√ß√£o do Œµ, matrizes de confus√£o e gr√°ficos de *trade-off*.

---

## **üìÇ Estrutura do Reposit√≥rio**

avalia_priv_acc_ml-dp_dp-sgd/
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ avalia_priv_acc_ml-dp_dp-sgd.ipynb # Notebook principal

---

## **üß™ Descri√ß√£o do Experimento**

O c√≥digo presente no notebook executa:

### **1) Carregamento do CIFAR-10**
Convers√£o para tensores e inicializa√ß√£o dos *dataloaders* de treino e teste.

### **2) Defini√ß√£o do Modelo (CNN personalizada)**
Modelo `DPCNN`, com camadas convolucionais, *GroupNorm*, *ReLU*, *MaxPool* e dois classificadores lineares.

### **3) Treinamento sem Privacidade (Baseline)**
Ser√° adicionada uma c√©lula que treina o modelo com SGD **sem** DP-SGD, para permitir compara√ß√£o direta.

### **4) Treinamento com DP-SGD**
Utiliza√ß√£o do **Opacus** com `noise_multiplier` variando conforme os cen√°rios:

| Cen√°rio               | Noise Multiplier (œÉ) |
|----------------------|----------------------|
| Privacidade Fraca    | 0.3                  |
| Privacidade M√©dia    | 0.8                  |
| Privacidade Forte    | 1.5                  |

O c√≥digo coleta:

- *Loss* por √©poca  
- Acur√°cia por √©poca  
- Œµ (epsilon) por √©poca  
- Matriz de Confus√£o final  
- Resultados consolidados em `df_results`

### **5) Gera√ß√£o de Gr√°ficos**
O notebook produz:

- Curva de *loss* por cen√°rio  
- Curva de acur√°cia por cen√°rio  
- Evolu√ß√£o do Œµ  
- Matriz de confus√£o para cada cen√°rio  
- Gr√°fico Œµ √ó acur√°cia  
- Gr√°fico œÉ √ó acur√°cia  
- Gr√°fico œÉ √ó Œµ  
- Gr√°ficos comparativos finais (barras)

---

## **üìä Resultados Esperados**

O treinamento DP-SGD demonstra empiricamente:

- **Quanto maior o ru√≠do**, **maior a privacidade** (menor Œµ).  
- **Quanto maior a privacidade**, **menor a acur√°cia** ‚Äî devido ao impacto do ru√≠do no gradiente.  
- A qualidade dos modelos sem DP √© superior, por√©m **n√£o oferecem prote√ß√£o formal contra ataques de infer√™ncia**.

Os resultados completos podem ser visualizados no notebook.

---

## **‚ñ∂Ô∏è Como Executar o Notebook**

1. Abra o link do Google Colab.  
2. Selecione ‚ÄúExecutar tudo‚Äù.  
3. Certifique-se de que a GPU est√° ativada no ambiente do Colab.  
4. Caso execute localmente:
   ```bash
   pip install opacus torch torchvision seaborn scikit-learn

---

üîí **Sobre Privacidade Diferencial e DP-SGD**
O m√©todo DP-SGD, proposto inicialmente por **Abadi et al. (2016)**, aplica:
* **Clipping dos gradientes**
* **Ru√≠do Gaussiano** proporcional ao n√≠vel de privacidade desejado
* **Rastreamento do Œµ** ao longo do treinamento
Este reposit√≥rio demonstra a implementa√ß√£o pr√°tica e sua an√°lise experimental.

---

üìú **Licen√ßa Recomendada**
A exig√™ncia √© que **os autores sejam sempre mencionados.**
A licen√ßa que melhor atende esse requisito √©:

---

üëâ **Licen√ßa BSD 3-Clause**
Ela permite uso, modifica√ß√£o e redistribui√ß√£o, desde que **o aviso de copyright seja mantido** ‚Äî cumprindo exatamente sua exig√™ncia.

**BSD 3-Clause License**

Copyright (c) 2025, Gustavo Gobi Martinelli
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.
3. Neither the name of the authors nor the names of its contributors may be used
   to endorse or promote products derived from this software without specific
   prior written permission.

---

üìû **Contato dos Autores**

**Gustavo Gobi Martinelli**
Email: [gustavomartinelli@gmail.com](gustavomartinelli@gmail.com)

**Prof. Rodolfo da Silva Villa√ßa**
Email: [rodolfo.villaca@inf.ufes.br](rodolfo.villaca@inf.ufes.br)

---

üìù **Observa√ß√£o Final**

Este README serve como documenta√ß√£o p√∫blica do experimento e dos resultados apresentados no artigo.
Caso deseje contribuir, testar varia√ß√µes ou reportar issues, fique √† vontade para abrir uma discuss√£o no reposit√≥rio.
